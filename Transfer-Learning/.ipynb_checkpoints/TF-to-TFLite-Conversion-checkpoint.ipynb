{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Ref: https://www.tensorflow.org/guide/extend/model_files#freezing\n",
    "# Ref: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py\n",
    "# optimize_for_inference_lib: contains functions for creating optimized protobuf file\n",
    "from tensorflow.python.tools import freeze_graph, optimize_for_inference_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Graph Definition\n",
    "input_graph_def = tf.GraphDef()\n",
    "\n",
    "# Optimize Frozen Model for Inference\n",
    "# Open \"frozen_linear_regression.pb\" model\n",
    "with tf.gfile.Open('./retrained_graph.pb', 'rb') as f:\n",
    "    # Read data from frozen model file\n",
    "    data = f.read()\n",
    "    # Parse model data from \"data\"\n",
    "    input_graph_def.ParseFromString(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['final_result=>Softmax']\n"
     ]
    }
   ],
   "source": [
    "# List I/O Node Names\n",
    "print([n.name + '=>' +  n.op for n in input_graph_def.node if n.op in ( 'Softmax','DecodeJpeg/contents')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anujdutt/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n"
     ]
    }
   ],
   "source": [
    "# Output Graph Definition\n",
    "# Save the .pb model as optimized model for inference\n",
    "\n",
    "# Optimizing for inference does the following:\n",
    "# > Removing operations used only for training like checkpoint saving.\n",
    "# > Stripping out parts of the graph that are never reached.\n",
    "# > Removing debug operations like CheckNumerics.\n",
    "\n",
    "# input_node_names: name of node used as input during inference i.e. \"input_features\" i.e. \"X\"\n",
    "# output_node_names: name of node providing output during inference i.e. \"y_out\"\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(input_graph_def=input_graph_def,\n",
    "                                                                     input_node_names=[\"DecodeJpeg/contents\"],\n",
    "                                                                     output_node_names=['final_result'],\n",
    "                                                                     placeholder_type_enum=tf.float32.as_datatype_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-08d6be12b35d>:5: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "Optimized Model Saved at ./saved_model/optimized_frozen_model.pb\n"
     ]
    }
   ],
   "source": [
    "# FastGFile is same a GFile\n",
    "# Ref: https://github.com/tensorflow/tensorflow/issues/12663\n",
    "# Define the name and mode for the optimized frozen model file\n",
    "file = tf.gfile.FastGFile(name=\"./optimized_frozen_model.pb\",\n",
    "                          mode='w')\n",
    "\n",
    "# Save the optimized graph def as an optimized frozen model\n",
    "file.write(file_content=output_graph_def.SerializeToString())\n",
    "\n",
    "print(\"Optimized Model Saved at ./saved_model/optimized_frozen_model.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape of tensor 'DecodeJpeg/contents' cannot be changed from () to [224]. Shapes must be equal rank, but are 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    536\u001b[0m           \u001b[0mdim_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m           unknown_shape)\n\u001b[0m\u001b[1;32m    538\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 0 and 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mset_tensor_shapes\u001b[0;34m(tensors, shapes)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m           \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    539\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 0 and 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a121e7036151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                       \u001b[0minput_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DecodeJpeg/contents\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                       \u001b[0moutput_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                       input_shapes={'DecodeJpeg/contents': [224]})\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Quantize Trained Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m    286\u001b[0m           output_tensors = _get_tensors_from_tensor_names(\n\u001b[1;32m    287\u001b[0m               sess.graph, output_arrays)\n\u001b[0;32m--> 288\u001b[0;31m           \u001b[0m_set_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mset_tensor_shapes\u001b[0;34m(tensors, shapes)\u001b[0m\n\u001b[1;32m    218\u001b[0m                      \"{2}. {3}\".format(name, tensor.get_shape(), shape,\n\u001b[1;32m    219\u001b[0m                                        str(error)))\n\u001b[0;32m--> 220\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of tensor 'DecodeJpeg/contents' cannot be changed from () to [224]. Shapes must be equal rank, but are 0 and 1"
     ]
    }
   ],
   "source": [
    "# Convert Frozen Model to TFLite Model\n",
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file=\"./retrained_graph.pb\",\n",
    "                                                      input_arrays=[\"DecodeJpeg/contents\"],\n",
    "                                                      output_arrays=['final_result'],\n",
    "                                                      input_shapes={'DecodeJpeg/contents': [224]})\n",
    "\n",
    "# Quantize Trained Model\n",
    "converter.post_training_quantize = True\n",
    "\n",
    "# Convert Frozen Model to TFLite Model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save TFLite Model\n",
    "open(\"./optimized_frozen_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "print(\"Optimized TFLite Model Saved at ./optimized_frozen_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
