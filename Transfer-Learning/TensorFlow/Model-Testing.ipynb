{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "Now that we have a model for classifying sounds, lets apply it to classify sounds from a microphone. The tensorflow retraining example has a script for labelling images.\n",
    "\n",
    "We modify this script to label sounds from the microphone. First, the script streams audio from the mic using pyaudio, and uses the webrtcvad package to detect if sound is present at the microphone. If a sound is present it is recorded for 3 seconds, and then converted into a spectrogram and finally labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webrtcvad in /Users/anujdutt/miniconda3/envs/deeplearning/lib/python3.7/site-packages (2.0.10)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install webrtcvad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import webrtcvad\n",
    "import pyaudio\n",
    "import wave\n",
    "import os, sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad = webrtcvad.Vad()\n",
    "vad.set_mode(2)\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 32000\n",
    "CHUNK = 960\n",
    "RECORD_SECONDS = 3\n",
    "WAVE_OUTPUT_FILENAME = \"file.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# start Recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-a90070588f57>:2: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "# Unpersists graph from file\n",
    "with tf.gfile.FastGFile(\"./retrained_graph.pb\", 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.75024)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.34954)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "drilling (score = 0.42318)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "air conditioner (score = 0.29856)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.50650)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.36311)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "air conditioner (score = 0.26999)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.42728)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.41173)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.63066)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "drilling (score = 0.29734)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.40172)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.29440)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.73827)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.38500)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.47050)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.53826)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.67797)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.60852)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.81567)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.88696)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.88684)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "street music (score = 0.26847)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.79159)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.97996)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.81002)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.97027)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.97769)\n",
      "\n",
      "recording...\n",
      "finished recording\n",
      "dog bark (score = 0.93106)\n",
      "\n",
      "recording...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-219e0dcd7ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recording...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRATE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mCHUNK\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mRECORD_SECONDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished recording\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Feed the image_data as input to the graph and get first prediction\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "    while True:\n",
    "\n",
    "        frames = []\n",
    "        frameCount = 0\n",
    "\n",
    "        while frameCount < 5:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "\n",
    "            if vad.is_speech(data, RATE):\n",
    "                frameCount+=1;\n",
    "            else:\n",
    "                frameCount = 0;\n",
    "            # print frameCount\n",
    "\n",
    "        print(\"recording...\")\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "        print(\"finished recording\")\n",
    "\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "        # change this as you see fit\n",
    "        audio_path = 'file.wav'\n",
    "        image_path = 'tmp/tmp.jpg'\n",
    "\n",
    "        y, sr = librosa.load(audio_path)\n",
    "\n",
    "        # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "        S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\n",
    "        # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "        log_S = librosa.core.amplitude_to_db(S, ref=np.max)\n",
    "\n",
    "        # Make a new figure\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "\n",
    "        # Display the spectrogram on a mel scale\n",
    "        # sample rate and hop length parameters are used to render the time axis\n",
    "        librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "        # Make the figure layout compact\n",
    "\n",
    "        #plt.show()\n",
    "        plt.savefig(image_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Read in the image_data\n",
    "        image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "\n",
    "        # Loads label file, strips off carriage return\n",
    "        label_lines = [line.rstrip() for line\n",
    "                           in tf.gfile.GFile(\"./retrained_labels.txt\")]\n",
    "\n",
    "        predictions = sess.run(softmax_tensor, \\\n",
    "                 {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "        # Sort to show labels of first prediction in order of confidence\n",
    "        top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "\n",
    "        print('%s (score = %.5f)' % (label_lines[top_k[0]], predictions[0][top_k[0]]))\n",
    "        print(\"\")\n",
    "\n",
    "# stop Recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
